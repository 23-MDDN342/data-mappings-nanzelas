[![Review Assignment Due Date](https://classroom.github.com/assets/deadline-readme-button-24ddc0f5d75046c5622901739e7c5dd533143b0c8e959d652212380cedb1ea36.svg)](https://classroom.github.com/a/HpplOQZx)
[![Open in Visual Studio Code](https://classroom.github.com/assets/open-in-vscode-718a45dd9cf7e7f842a935f5ebbe5719a5e09af4491e668f4dbf3b35d5cca122.svg)](https://classroom.github.com/online_ide?assignment_repo_id=15017002&assignment_repo_type=AssignmentRepo)
## 2024 MDDN342 Assignment 3: Data Mappings

**Part1:** I created two sketches to improve on the face from my project two, I don't think the original face would have rendered too well visually in this project. So I added some visual details to the original by fitting the shape more to the face for the next training attributes.

**Part2:** When I was mapping, It's adjusted visually according to the actual position of the features on a person's face. I made minor adjustments to the mapping of the face by looking at the face anchor points to get a more accurate positioning by calculating the spacing of the features. I decided to use sliders to control the spacing of the eyes, the position of the nose, how far the mouth opens and closes, the colour of the face and the presence or absence of hair

**Part3:** I found out through training that there was a mistake in the opening and closing of the mouth. I mapped mouths with different degrees of opening and closing with the difference being more pronounced and trained multiple times to ensure it had a pronounced degree of opening and closing.

**Final:** This project aims to create a minimalist style emoticon that adapts to various real-world and fictional scenarios using advanced AI and machine learning techniques. By mapping face images from different scenes, the project enhances the emoticon's usability and application.

**Key Features**
Advanced Face Mapping: Utilizes machine learning to map faces accurately, improving the quality and responsiveness of the emoticons.
Dynamic Slider Control: A sophisticated slider control system allows the emoticon to fit more application scenarios with real faces.
Face Coordinate Mapping: Adjusts the range of values to better map face coordinates to the mask, ensuring precise alignment and expression.
Comic Book Character Integration: Extends the emoticon's application to fictional characters, demonstrating its versatility beyond real-world faces.
Real-Time Face Anchors: Uses AI to capture face anchors and adjust emoticon features in real-time based on camera input.
Learning Outcomes
Machine Learning Techniques: Enhanced understanding and application of machine learning for face mapping and feature extraction.
Technical Coding Skills: Improved coding skills to handle complex face mapping and dynamic adjustments.
Face Coordinate Relationships: Deepened knowledge of mapping relationships and value adjustments for better mask application.

**Applications**
Create customizable and dynamic emoticons for social media interactions.
Enhance messaging apps with more expressive and personalized emojis.
Implement dynamic character expressions to enrich gaming experiences.
Utilize real-time face modifications in AR applications for a more immersive experience.

**Implementation**
Face Anchors Capture: Leveraging AI to capture face anchors accurately for dynamic emoticon adjustments.
Real-Time Mask Changes: Enabling real-time changes to mask styles based on detailed face analysis from the camera.

**Reflections**
Ensuring the system works effectively across a diverse range of faces and expressions remains a priority. Continuous testing and refinement are necessary to improve accuracy and inclusivity.
